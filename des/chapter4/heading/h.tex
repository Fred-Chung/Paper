\chapter{Bound Dirichlet Belief Model}\label{ccl}

\section{Introduction}
Unlike DirBN model which inference latent vairiables by propagating count matrix with Chinese Restaurant Table (CRT)
distribution.In DBN model,we can forward variable sampling stratrgy for model inference.
$$C_{i'..}^{l} \sim Multi(M^l;\pi_{i'.}^l \otimes w_{i'.}^l) \tag{1}$$
$$\pi_i^{l+1} \sim Dirihlet(\alpha_d +\sum_{i'}{C_{i'.i}})\tag{2}$$
\begin{itemize}
  \item Information pass from Topic i' to Topic i
  \item $\pi_{i'.}^l$ is the Topic-Word matrix in layer $l$
  \item All layer has same Topic number
  \item $w_{i'i}^l$ is the probability of Information distribution from topic i' to i
  \item This is the reconstruction process.
  \item  $\sum_{i'}{C_{i'.i}}$  is a (V*k) by 1 Vector.
\end{itemize}

 Poisson-Multinomial Equivalence:
 $$C_{i'ki}^{l} \sim Poisson(M^l \pi_{i'k}^l w_{i'i}^l)\tag{3}$$

\section{Inferene}
\begin{enumerate}
  \item Input matrix is topic-word matrix (K*N).Sampling $$\pi^{l}$$: Dirichlet posterior distribution(later)

  \item Sampling $C_{i'ki}^l$.
  $$P(C_{i'ki}^{l}|.) \sim \frac{(M^l \pi_{i'k}^l w_{i'i}^l)^{C_{i'ki}}}{C_{i'ki}!}$$

  $$P(\pi_i^{l+1}|C_{i'ki}^{l},..) = \frac{1}{B({\alpha_d +\sum_{i'}{C_{i'.i})}}} \prod^V \pi_{ik}^{\alpha_d+C_{i'ki}^l-1}$$

  The posterior distribution of $C_{i'ki}^{l}$ is:

  $$P(C_{i'ki}^{l}|.) \propto \frac{(M^l \pi_{i'k}^l w_{i'i}^l)^{C_{i'ki}}}{C_{i'ki}!} .\frac{1}{B({\alpha_d +\sum_{i'}{C_{i'.i})}}} \prod^V \pi_{ik}^{\alpha_d+C_{i'ki}^l-1} $$

  and

  $\sum_{i'}{C_{i'ki}} = M^l$  (normalize)

  \item Sampling $\pi_{i'}^l$,its posterior distribution is Dirichlet distribution.
  $$\sum_i{C_{i'ki}} \sim Multi(M^l;\pi_{i'.}^l)$$

  \item  Sampling $w$
  * Likelihood
  $$\sum_k{C_{i'ki}} \sim Multi(M^l;w_{i'.}^l)$$

  * Prior distribution

  $$W_{i'i} \sim Dirichlet(\alpha_w)$$

  * Posterior distribution

  $$p(w_{i'}|..) \sim Dirichlet(\alpha_w+w_{i'.})$$
\end{enumerate}
